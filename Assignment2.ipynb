{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlrose_hiive\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem Definitions\n",
    "OMFitness = mlrose_hiive.OneMax()\n",
    "OMProblemLength = 20\n",
    "OMProblem = mlrose_hiive.DiscreteOpt(length=OMProblemLength, fitness_fn=OMFitness)\n",
    "OMInit = np.random.choice([0, 1], size=(OMProblemLength,))\n",
    "\n",
    "coords = [(0, 0), (4, 0), (1, 2), (3, 4), (5, 3), \n",
    "            (3, 2), (1, 5), (2, 1), (1, 6), (7, 2), \n",
    "            (3, 3), (0, 4), (2, 3), (3, 9), (3, 1),\n",
    "            (1, 1), (2, 0), (5, 6), (7, 9), (7, 4)]\n",
    "TSProblemLength = 10\n",
    "coordsTrimmed = coords[:TSProblemLength]\n",
    "TSFitness = mlrose_hiive.TravellingSales(coords=coordsTrimmed)\n",
    "TSProblem = mlrose_hiive.TSPOpt(length=TSProblemLength, fitness_fn=TSFitness, maximize=False)\n",
    "TSInit = np.arange(TSProblemLength)\n",
    "\n",
    "FPFitness = mlrose_hiive.FourPeaks()\n",
    "FPProblemLength = 20\n",
    "FPProblem = mlrose_hiive.DiscreteOpt(length=FPProblemLength, fitness_fn=FPFitness)\n",
    "FPInit = np.random.choice([0, 1], size=(FPProblemLength,))\n",
    "\n",
    "fitnesses = [TSFitness, OMFitness, FPFitness]\n",
    "problems = [TSProblem, OMProblem, FPProblem]\n",
    "init_states = [TSInit, OMInit, FPInit]\n",
    "problemNames = [\"Travelling Salesman\", \"One Max\", \"Four Peaks\"]\n",
    "\n",
    "schedule = mlrose_hiive.GeomDecay()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitness and Fevals by Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = 2 # TS, OM, FP\n",
    "maxIters = 10000\n",
    "maxAttempts = 200\n",
    "popSize = 100\n",
    "\n",
    "HC_state, HC_fitness, HC_curve = mlrose_hiive.random_hill_climb(problems[prob], max_attempts=maxAttempts, max_iters=maxIters, restarts=10, init_state=None, curve=True, random_state=1)\n",
    "SA_state, SA_fitness, SA_curve = mlrose_hiive.simulated_annealing(problems[prob], schedule=schedule, max_attempts=maxAttempts, max_iters=maxIters, init_state=None, curve=True, random_state=1)\n",
    "GA_state, GA_fitness, GA_curve = mlrose_hiive.genetic_alg(problems[prob], pop_size=popSize, mutation_prob=0.1, max_attempts=maxAttempts, max_iters=maxIters, curve=True, random_state=1)\n",
    "MIMIC_state, MIMIC_fitness, MIMIC_curve = mlrose_hiive.mimic(problems[prob], pop_size=popSize, keep_pct=0.2, max_attempts=maxAttempts, max_iters=maxIters, curve=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitnesses = [HC_curve.T[0], SA_curve.T[0], GA_curve.T[0], MIMIC_curve.T[0]]\n",
    "fevals = [HC_curve.T[1], SA_curve.T[1], GA_curve.T[1], MIMIC_curve.T[1]]\n",
    "\n",
    "fig = plt.figure(1, [18, 6])\n",
    "ax = fig.add_subplot(121)\n",
    "ax.plot(np.arange(fitnesses[0].size), fitnesses[0])\n",
    "ax.plot(np.arange(fitnesses[1].size), fitnesses[1])\n",
    "ax.plot(np.arange(fitnesses[2].size), fitnesses[2])\n",
    "ax.plot(np.arange(fitnesses[3].size), fitnesses[3])\n",
    "ax.set_title(\"Fitness by Model using Fitness of \" + problemNames[prob])\n",
    "ax.set_xlabel(\"Iteration\")\n",
    "ax.set_ylabel(\"Fitness\")\n",
    "ax.legend([\"Random Hill Climbing\", \"Simulated Annealing\", \"Genetic Algorithm\", \"MIMIC\"])\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.plot(np.arange(fevals[0].size), fevals[0])\n",
    "ax2.plot(np.arange(fevals[1].size), fevals[1])\n",
    "ax2.plot(np.arange(fevals[2].size), fevals[2])\n",
    "ax2.plot(np.arange(fevals[3].size), fevals[3])\n",
    "ax2.set_title(\"Function Evaluations by Model using Fitness of \" + problemNames[prob])\n",
    "ax2.set_xlabel(\"Iteration\")\n",
    "ax2.set_ylabel(\"Function Evaluations\")\n",
    "ax2.legend([\"Random Hill Climbing\", \"Simulated Annealing\", \"Genetic Algorithm\", \"MIMIC\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitness and Runtime by Problem Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starts = [4, 4, 4] # TS, OM, FP\n",
    "ends = [20, 40, 40] # TS, OM, FP\n",
    "\n",
    "data = np.zeros((3, max(ends) - min(starts) + 1, 4)) # [problem][problemSize][algorithm]\n",
    "times = np.zeros((3, max(ends) - min(starts) + 1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob2 = 1 # TS, OM, FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in np.arange(3):\n",
    "    print(problemNames[j])\n",
    "    for i in np.arange(starts[j], ends[j] + 1):\n",
    "        print(i)\n",
    "        if j == 0:\n",
    "            coordsTrimmed2 = coords[:i]\n",
    "            test2_fitness = mlrose_hiive.TravellingSales(coords=coordsTrimmed2)\n",
    "            test2_problem = mlrose_hiive.TSPOpt(length=i, fitness_fn=test2_fitness, maximize=False)\n",
    "            test2_init = np.arange(i)\n",
    "        elif j == 1:\n",
    "            test2_fitness = mlrose_hiive.OneMax()\n",
    "            test2_problem = mlrose_hiive.DiscreteOpt(length=i, fitness_fn=test2_fitness)\n",
    "            test2_init = np.random.choice([0, 1], size=(i,))\n",
    "        elif j == 2:\n",
    "            test2_fitness = mlrose_hiive.FourPeaks()\n",
    "            test2_problem = mlrose_hiive.DiscreteOpt(length=i, fitness_fn=test2_fitness)\n",
    "            test2_init = np.random.choice([0, 1], size=(i,))\n",
    "\n",
    "        maxIters = 10000\n",
    "        popSize = 200\n",
    "\n",
    "        startTime = time.time()\n",
    "        HC_state, HC_fitness, _ = mlrose_hiive.random_hill_climb(test2_problem, max_attempts=100, max_iters=maxIters, restarts=10, init_state=test2_init, random_state=1)\n",
    "        t1 = time.time()\n",
    "        SA_state, SA_fitness, _ = mlrose_hiive.simulated_annealing(test2_problem, schedule=schedule, max_attempts=100, max_iters=maxIters, init_state=test2_init, random_state=1)\n",
    "        t2 = time.time()\n",
    "        GA_state, GA_fitness, _ = mlrose_hiive.genetic_alg(test2_problem, pop_size=popSize, mutation_prob=0.1, max_attempts=100, max_iters=maxIters, random_state=1)\n",
    "        t3 = time.time()\n",
    "        MIMIC_state, MIMIC_fitness, _ = mlrose_hiive.mimic(test2_problem, pop_size=popSize, keep_pct=0.2, max_attempts=100, max_iters=maxIters, random_state=1)\n",
    "        t4 = time.time()\n",
    "\n",
    "        data[j][:][i - starts[prob2]] = [HC_fitness, SA_fitness, GA_fitness, MIMIC_fitness]\n",
    "        times[j][:][i - starts[prob2]] = [t1 - startTime, t2 - t1, t3 - t2, t4 - t3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotProb = 2 # TS, OM, FP\n",
    "\n",
    "xax = np.arange(starts[plotProb], ends[plotProb] + 1)\n",
    "sampleNum = ends[plotProb] - starts[plotProb] + 1\n",
    "\n",
    "probData = data[plotProb][:sampleNum][:]\n",
    "probTime = times[plotProb][:sampleNum][:]\n",
    "\n",
    "fig = plt.figure(1, [12, 6])\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(xax, probData.T[0])\n",
    "ax.plot(xax, probData.T[1])\n",
    "ax.plot(xax, probData.T[2])\n",
    "ax.plot(xax, probData.T[3])\n",
    "ax.set_title(\"Fitness by Problem Size using Fitness of \" + problemNames[plotProb])\n",
    "ax.set_xlabel(\"Problem Size\")\n",
    "ax.set_ylabel(\"Fitness\")\n",
    "ax.legend([\"Hill Climbing\", \"Simulated Annealing\", \"Genetic Algorithm\", \"MIMIC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotProb = 2 # TS, OM, FP\n",
    "\n",
    "xax = np.arange(starts[plotProb], ends[plotProb] + 1)\n",
    "sampleNum = ends[plotProb] - starts[plotProb] + 1\n",
    "\n",
    "probData = data[plotProb][:sampleNum][:]\n",
    "probTime = times[plotProb][:sampleNum][:]\n",
    "\n",
    "fig = plt.figure(1, [12, 6])\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(xax, probTime.T[0])\n",
    "ax.plot(xax, probTime.T[1])\n",
    "ax.plot(xax, probTime.T[2])\n",
    "ax.plot(xax, probTime.T[3])\n",
    "ax.set_title(\"Runtime by Model using Fitness of \" + problemNames[plotProb])\n",
    "ax.set_xlabel(\"Problem Size\")\n",
    "ax.set_ylabel(\"Runtime\")\n",
    "ax.legend([\"Random Hill Climbing\", \"Simulated Annealing\", \"Genetic Algorithm\", \"MIMIC\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "\n",
    "irisData = iris.data.T[:2].T\n",
    "irisTarget = iris.target\n",
    "\n",
    "trainFeatures, testFeatures, trainTargets, testTargets = train_test_split(irisData, irisTarget, test_size = 0.2, random_state = 1)\n",
    "\n",
    "one_hot = OneHotEncoder()\n",
    "trainTargets = np.asarray(one_hot.fit_transform(trainTargets.reshape(-1, 1)).todense())\n",
    "testTargets = np.asarray(one_hot.fit_transform(testTargets.reshape(-1, 1)).todense())\n",
    "\n",
    "nn_model1 = mlrose_hiive.NeuralNetwork(hidden_nodes=[4], activation='relu', algorithm='random_hill_climb', \n",
    "                                max_iters=100000, bias=True, is_classifier=True, learning_rate=0.1, \n",
    "                                early_stopping=True, clip_max=5, max_attempts=100, random_state=None, curve=True, restarts=100)\n",
    "\n",
    "nn_model1.fit(trainFeatures, trainTargets)\n",
    "\n",
    "nn1trainPred = nn_model1.predict(trainFeatures)\n",
    "trainAccuracy1 = accuracy_score(nn1trainPred, trainTargets)\n",
    "\n",
    "nn1TestPred = nn_model1.predict(testFeatures)\n",
    "testAccuracy1 = accuracy_score(nn1TestPred, testTargets)\n",
    "\n",
    "print(trainAccuracy1, testAccuracy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model2 = mlrose_hiive.NeuralNetwork(hidden_nodes=[4], activation='relu', algorithm='simulated_annealing', \n",
    "                                max_iters=100000, bias=True, is_classifier=True, learning_rate=0.1, \n",
    "                                early_stopping=True, clip_max=5, max_attempts=100, random_state=1, curve=True)\n",
    "nn_model2.fit(trainFeatures, trainTargets)\n",
    "\n",
    "nn2trainPred = nn_model2.predict(trainFeatures)\n",
    "trainAccuracy2 = accuracy_score(nn2trainPred, trainTargets)\n",
    "nn2TestPred = nn_model2.predict(testFeatures)\n",
    "testAccuracy2 = accuracy_score(nn2TestPred, testTargets)\n",
    "\n",
    "print(trainAccuracy2, testAccuracy2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model3 = mlrose_hiive.NeuralNetwork(hidden_nodes=[4], activation='relu', algorithm='genetic_alg', \n",
    "                                max_iters=100000, bias=True, is_classifier=True, learning_rate=0.1, \n",
    "                                early_stopping=True, clip_max=5, max_attempts=100, random_state=1, pop_size=200, curve=True)\n",
    "nn_model3.fit(trainFeatures, trainTargets)\n",
    "\n",
    "nn3trainPred = nn_model3.predict(trainFeatures)\n",
    "trainAccuracy3 = accuracy_score(nn3trainPred, trainTargets)\n",
    "nn3TestPred = nn_model3.predict(testFeatures)\n",
    "testAccuracy3 = accuracy_score(nn3TestPred, testTargets)\n",
    "\n",
    "print(trainAccuracy3, testAccuracy3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NNfitnesses = [nn_model1.fitness_curve.T[0], nn_model2.fitness_curve.T[0], nn_model3.fitness_curve.T[0]]\n",
    "NNfevals = [nn_model1.fitness_curve.T[1], nn_model2.fitness_curve.T[1], nn_model3.fitness_curve.T[1]]\n",
    "\n",
    "fig = plt.figure(1, [18, 8])\n",
    "ax = fig.add_subplot(121)\n",
    "ax.plot(NNfitnesses[0])\n",
    "ax.plot(NNfitnesses[1])\n",
    "ax.plot(NNfitnesses[2])\n",
    "\n",
    "ax.set_title(\"Neural Net Weight Fitting Fitness over Iteration\")\n",
    "ax.set_xlabel(\"Iteration\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.legend([\"Random Hill Climbing\", \"Simulated Annealing\", \"Genetic Algorithm\"])\n",
    "\n",
    "ax = fig.add_subplot(122)\n",
    "ax.plot(NNfevals[0])\n",
    "ax.plot(NNfevals[1])\n",
    "ax.plot(NNfevals[2])\n",
    "\n",
    "ax.set_title(\"Fitness Evals over Iteration\")\n",
    "ax.set_xlabel(\"Iteration\")\n",
    "ax.set_ylabel(\"Function Evaluations\")\n",
    "ax.legend([\"Random Hill Climbing\", \"Simulated Annealing\", \"Genetic Algorithm\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
